{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: How many people live under the dominance area of each shopping center? (additional 5 points available!)\n",
    "\n",
    "Find out how many people live under the dominance area of each shopping center. \n",
    "\n",
    "- Check out week 3 materials for reading in population grid from [HSY wfs](https://www.hsy.fi/fi/asiantuntijalle/avoindata/karttapalvelu/Sivut/Avoimet-rajapinnat.aspx).\n",
    "- Aggregate your dominance areas into a unified geometries using [`dissolve()`](http://geopandas.org/aggregation_with_dissolve.html#dissolve-example) -function in Geopandas before joining with the population data\n",
    "- Make the spatial join using `intersect`as the condition\n",
    "\n",
    "You can freely organize your code into the code cells below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import glob\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import CRS\n",
    "import requests\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and import shopping centers data and population data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "236c7837ce483f83f8e47c925a248adb",
     "grade": false,
     "grade_id": "pop_data",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#1 Read shopping center data file (file made in problem 2)\n",
    "shopping_center_data = gpd.read_file(\"shopping_center_data.shp\")\n",
    "\n",
    "# Drop all the columns except dominant_service and geometry\n",
    "shopping_center_data = shopping_center_data[[\"dominant_s\", \"geometry\"]]\n",
    "\n",
    "# Rename column dominant_s back to dominant_service\n",
    "shopping_center_data = shopping_center_data.rename(columns={'dominant_s': 'dominant_service'})\n",
    "\n",
    "#2 Read population grid data\n",
    "\n",
    "# Specify the url for web feature service\n",
    "url = 'https://kartta.hsy.fi/geoserver/wfs'\n",
    "\n",
    "# Specify parameters (read data in json format).\n",
    "# Available feature types in this particular data source: http://geo.stat.fi/geoserver/vaestoruutu/wfs?service=wfs&version=2.0.0&request=describeFeatureType\n",
    "params = dict(service='WFS',\n",
    "              version='2.0.0',\n",
    "              request='GetFeature',\n",
    "              typeName='asuminen_ja_maankaytto:Vaestotietoruudukko_2018',\n",
    "              outputFormat='json')\n",
    "\n",
    "# Fetch data from WFS using requests\n",
    "r = requests.get(url, params=params)\n",
    "\n",
    "# Create GeoDataFrame from geojson\n",
    "pop = gpd.GeoDataFrame.from_features(geojson.loads(r.content))\n",
    "\n",
    "# Drop all the columns exceps asukkaita and geometry\n",
    "pop = pop[[\"asukkaita\", \"geometry\"]]\n",
    "\n",
    "# Rename column asukkaita to pop18\n",
    "pop = pop.rename(columns={'asukkaita': 'pop18'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2bdb62974e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mpop_2010\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pop_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1997\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#pop_2011 = get_pop_data(2011)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#pop_2012 = get_pop_data(2012)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2bdb62974e84>\u001b[0m in \u001b[0;36mget_pop_data\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Create GeoDataFrame from geojson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeojson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Define coordinate reference system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/geojson/codec.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, parse_constant, object_hook, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                       \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                       \u001b[0mparse_constant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_constant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                       **kwargs)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparse_constant\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create function to get population data\n",
    "def get_pop_data(year):\n",
    "    \n",
    "    # Specify the url for web feature service\n",
    "    url = 'https://kartta.hsy.fi/geoserver/wfs'\n",
    "    \n",
    "    # Specify parameters (read data in json format).\n",
    "    # Available feature types in this particular data source: http://geo.stat.fi/geoserver/vaestoruutu/wfs?service=wfs&version=2.0.0&request=describeFeatureType\n",
    "    params = dict(service='WFS', version='2.0.0', request='GetFeature', typeName='asuminen_ja_maankaytto:Vaestoruudukko_'+str(year), outputFormat='json')\n",
    "\n",
    "    # Fetch data from WFS using requests\n",
    "    r = requests.get(url, params=params)\n",
    "\n",
    "    # Create GeoDataFrame from geojson\n",
    "    pop = gpd.GeoDataFrame.from_features(geojson.loads(r.content))\n",
    "    \n",
    "    # Define coordinate reference system\n",
    "    pop.crs = CRS.from_epsg(3879).to_wkt()\n",
    "    \n",
    "    # Drop all the columns exceps asukkaita and geometry\n",
    "    pop = pop[[\"index\", \"asukkaita\", \"geometry\"]]\n",
    "\n",
    "    # Rename column asukkaita to pop18\n",
    "    pop = pop.rename(columns={'asukkaita': 'pop'+str(year)})\n",
    "    \n",
    "    # Return result geodataframe\n",
    "    return pop\n",
    "\n",
    "\n",
    "pop_2010 = get_pop_data(1997)\n",
    "#pop_2011 = get_pop_data(2011)\n",
    "#pop_2012 = get_pop_data(2012)\n",
    "#pop_2013 = get_pop_data(2013)\n",
    "#pop_2014 = get_pop_data(2014)\n",
    "pop_2015 = get_pop_data(2015)\n",
    "pop_2016 = get_pop_data(2016)\n",
    "pop_2017 = get_pop_data(2017)\n",
    "pop_2018 = get_pop_data(2018)\n",
    "pop_2019 = get_pop_data(2019)\n",
    "\n",
    "pop_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set coordinate reference system to EPSG 3879 to both geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a74ac5f00878316639ced6d4824e667",
     "grade": false,
     "grade_id": "dissolve",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the crs same on boths dataframes? Result: False\n",
      "Is the crs same on boths dataframes? Result: True\n"
     ]
    }
   ],
   "source": [
    "# Define crs\n",
    "pop.crs = CRS.from_epsg(3879).to_wkt()\n",
    "\n",
    "# Are the layers in the same projection?\n",
    "print(\"Is the crs same on boths dataframes? Result:\", pop.crs == shopping_center_data.crs)\n",
    "\n",
    "# Reproject geodata to coordinates to population crs\n",
    "shopping_center_data = shopping_center_data.to_crs(pop.crs)\n",
    "\n",
    "# Are the layers now in the same projection?\n",
    "print(\"Is the crs same on boths dataframes? Result:\", pop.crs == shopping_center_data.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce80986e449f2a172e8283af1dcef16a",
     "grade": false,
     "grade_id": "sjoin",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "#### Aggregate shopping centers dominance areas into a unified geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdfe29c8bca6773b464820839ec8f8dc",
     "grade": false,
     "grade_id": "final_result",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominant_service</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Dixi</th>\n",
       "      <td>MULTIPOLYGON (((25508886.745 6684266.016, 2550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Forum</th>\n",
       "      <td>MULTIPOLYGON (((25495548.583 6670352.148, 2549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_IsoOmena</th>\n",
       "      <td>MULTIPOLYGON (((25477492.450 6671806.572, 2547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Itis</th>\n",
       "      <td>MULTIPOLYGON (((25500759.604 6671760.862, 2550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Jumbo</th>\n",
       "      <td>MULTIPOLYGON (((25506167.581 6683182.834, 2550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Myyrmanni</th>\n",
       "      <td>MULTIPOLYGON (((25495351.703 6676850.706, 2549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Ruoholahti</th>\n",
       "      <td>MULTIPOLYGON (((25487452.020 6673359.116, 2548...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            geometry\n",
       "dominant_service                                                    \n",
       "pt_r_t_Dixi        MULTIPOLYGON (((25508886.745 6684266.016, 2550...\n",
       "pt_r_t_Forum       MULTIPOLYGON (((25495548.583 6670352.148, 2549...\n",
       "pt_r_t_IsoOmena    MULTIPOLYGON (((25477492.450 6671806.572, 2547...\n",
       "pt_r_t_Itis        MULTIPOLYGON (((25500759.604 6671760.862, 2550...\n",
       "pt_r_t_Jumbo       MULTIPOLYGON (((25506167.581 6683182.834, 2550...\n",
       "pt_r_t_Myyrmanni   MULTIPOLYGON (((25495351.703 6676850.706, 2549...\n",
       "pt_r_t_Ruoholahti  MULTIPOLYGON (((25487452.020 6673359.116, 2548..."
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate your dominance areas into a unified geometries\n",
    "shopping_centers_areas = shopping_center_data.dissolve(by='dominant_service')\n",
    "\n",
    "# Show geodataframe\n",
    "shopping_centers_areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the spatial join using intersectas the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_right</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Dixi</th>\n",
       "      <td>201962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Forum</th>\n",
       "      <td>252721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_IsoOmena</th>\n",
       "      <td>174969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Itis</th>\n",
       "      <td>201066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Jumbo</th>\n",
       "      <td>69613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Myyrmanni</th>\n",
       "      <td>203275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt_r_t_Ruoholahti</th>\n",
       "      <td>83754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pop18\n",
       "index_right              \n",
       "pt_r_t_Dixi        201962\n",
       "pt_r_t_Forum       252721\n",
       "pt_r_t_IsoOmena    174969\n",
       "pt_r_t_Itis        201066\n",
       "pt_r_t_Jumbo        69613\n",
       "pt_r_t_Myyrmanni   203275\n",
       "pt_r_t_Ruoholahti   83754"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a spatial join between shopping_center_areas and pop dataframes \n",
    "shopping_center_population =  gpd.sjoin(pop, shopping_centers_areas, how=\"inner\", op=\"intersects\")\n",
    "\n",
    "# Group data by shopping center name and calculate population sum\n",
    "shopping_center_population = shopping_center_population.groupby(\"index_right\").sum()\n",
    "\n",
    "# Show dataframe\n",
    "shopping_center_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count and print number of people in each shopping centers dominant areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201962 people live in the dominance area of shopping center Dixi.\n",
      "\n",
      "252721 people live in the dominance area of shopping center Forum.\n",
      "\n",
      "174969 people live in the dominance area of shopping center IsoOmena.\n",
      "\n",
      "201066 people live in the dominance area of shopping center Itis.\n",
      "\n",
      "69613 people live in the dominance area of shopping center Jumbo.\n",
      "\n",
      "203275 people live in the dominance area of shopping center Myyrmanni.\n",
      "\n",
      "83754 people live in the dominance area of shopping center Ruoholahti.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in shopping_center_population.iterrows():\n",
    "    name = re.search('pt_r_t_(\\D*)', index).group(1)\n",
    "    print(row[\"pop18\"], \"people live in the dominance area of shopping center\", name + \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to print the answers in this notebook :)\n",
    "\n",
    "### Extra bonus task\n",
    "\n",
    "Repeat problem 2 and 3 for car accessibility! No extra points available for this, but you can for example start thinking if you want to make the final assignment related to this topic :)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
